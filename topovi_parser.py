"""
–ü–∞—Ä—Å–µ—Ä –¥–ª—è —Å–∞–π—Ç—É topovi.com.ua
–í–µ—Ä—Å—ñ—è 3.0 - –∑ –∑–∞–ø–∏—Å–æ–º —É —Ñ–∞–π–ª —Ç–∞ –ø—Ä–æ–¥–æ–≤–∂–µ–Ω–Ω—è–º –∑ –º—ñ—Å—Ü—è –∑—É–ø–∏–Ω–∫–∏
"""

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.service import Service
from bs4 import BeautifulSoup
import pandas as pd
import time
from tqdm import tqdm
import os
import json

class TopoviParser:
    def __init__(self, output_file='topovi_products.xlsx'):
        """–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –ø–∞—Ä—Å–µ—Ä–∞"""
        self.output_file = output_file
        self.progress_file = 'progress.json'
        self.driver = None
        self.wait = None
        self.processed_urls = set()
        self.init_driver()
        self.load_progress()
        
    def init_driver(self):
        """–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –¥—Ä–∞–π–≤–µ—Ä–∞ –±—Ä–∞—É–∑–µ—Ä–∞"""
        options = webdriver.ChromeOptions()
        # –ó–∞–∫–æ–º–µ–Ω—Ç—É–π—Ç–µ –Ω–∞—Å—Ç—É–ø–Ω–∏–π —Ä—è–¥–æ–∫, —è–∫—â–æ —Ö–æ—á–µ—Ç–µ –±–∞—á–∏—Ç–∏ –±—Ä–∞—É–∑–µ—Ä
        options.add_argument('--headless')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
        options.add_argument('--disable-gpu')
        options.add_argument('--window-size=1920,1080')
        
        try:
            service = Service(ChromeDriverManager().install())
            self.driver = webdriver.Chrome(service=service, options=options)
            self.wait = WebDriverWait(self.driver, 15)
            print("‚úÖ –ë—Ä–∞—É–∑–µ—Ä —É—Å–ø—ñ—à–Ω–æ –∑–∞–ø—É—â–µ–Ω–æ")
        except Exception as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–ø—É—Å–∫—É –±—Ä–∞—É–∑–µ—Ä–∞: {e}")
            raise
    
    def load_progress(self):
        """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –ø—Ä–æ–≥—Ä–µ—Å –∑ —Ñ–∞–π–ª—É"""
        if os.path.exists(self.progress_file):
            try:
                with open(self.progress_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.processed_urls = set(data.get('processed_urls', []))
                print(f"üìÇ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –ø—Ä–æ–≥—Ä–µ—Å: {len(self.processed_urls)} —Ç–æ–≤–∞—Ä—ñ–≤ –≤–∂–µ –æ–±—Ä–æ–±–ª–µ–Ω–æ")
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—å –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –ø—Ä–æ–≥—Ä–µ—Å: {e}")
                self.processed_urls = set()
        else:
            print("üÜï –ü–æ—á–∞—Ç–æ–∫ –Ω–æ–≤–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥—É")
    
    def save_progress(self):
        """–ó–±–µ—Ä—ñ–≥–∞—î –ø—Ä–æ–≥—Ä–µ—Å —É —Ñ–∞–π–ª"""
        try:
            with open(self.progress_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'processed_urls': list(self.processed_urls)
                }, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –ø—Ä–æ–≥—Ä–µ—Å—É: {e}")
    
    def restart_driver(self):
        """–ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –¥—Ä–∞–π–≤–µ—Ä–∞ –ø—Ä–∏ –ø–æ–º–∏–ª–∫–∞—Ö"""
        print("üîÑ –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –±—Ä–∞—É–∑–µ—Ä–∞...")
        try:
            if self.driver:
                self.driver.quit()
        except:
            pass
        
        time.sleep(3)
        self.init_driver()
        
    def load_all_products(self, url):
        """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –≤—Å—ñ —Ç–æ–≤–∞—Ä–∏, –Ω–∞—Ç–∏—Å–∫–∞—é—á–∏ –∫–Ω–æ–ø–∫—É 'Load more'"""
        print("üåê –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Å—Ç–æ—Ä—ñ–Ω–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó...")
        
        max_retries = 3
        for attempt in range(max_retries):
            try:
                self.driver.get(url)
                time.sleep(3)
                break
            except WebDriverException as e:
                if attempt < max_retries - 1:
                    print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Å—Ç–æ—Ä—ñ–Ω–∫–∏, —Å–ø—Ä–æ–±–∞ {attempt + 2}/{max_retries}...")
                    self.restart_driver()
                else:
                    raise
        
        # –ù–∞—Ç–∏—Å–∫–∞—î–º–æ –∫–Ω–æ–ø–∫—É "Load more" –¥–æ–∫–∏ –≤–æ–Ω–∞ —î
        click_count = 0
        consecutive_errors = 0
        
        while consecutive_errors < 3:
            try:
                # –®—É–∫–∞—î–º–æ –∫–Ω–æ–ø–∫—É load-more
                load_more_btn = self.driver.find_element(By.CSS_SELECTOR, '.btn.load-more')
                
                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ –∫–Ω–æ–ø–∫–∞ –≤–∏–¥–∏–º–∞ —ñ –∞–∫—Ç–∏–≤–Ω–∞
                if load_more_btn.is_displayed():
                    # –°–∫—Ä–æ–ª–∏–º–æ –¥–æ –∫–Ω–æ–ø–∫–∏
                    self.driver.execute_script("arguments[0].scrollIntoView(true);", load_more_btn)
                    time.sleep(0.5)
                    
                    # –ö–ª—ñ–∫–∞—î–º–æ
                    load_more_btn.click()
                    click_count += 1
                    print(f"üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –±–ª–æ–∫ #{click_count}...")
                    time.sleep(2)
                    consecutive_errors = 0  # –°–∫–∏–¥–∞—î–º–æ –ª—ñ—á–∏–ª—å–Ω–∏–∫ –ø–æ–º–∏–ª–æ–∫
                else:
                    break
                    
            except NoSuchElementException:
                print("‚úÖ –í—Å—ñ —Ç–æ–≤–∞—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ!")
                break
            except Exception as e:
                consecutive_errors += 1
                print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –Ω–∞—Ç–∏—Å–∫–∞–Ω–Ω—ñ ({consecutive_errors}/3): {e}")
                time.sleep(2)
        
        # –û—Ç—Ä–∏–º—É—î–º–æ HTML –ø—ñ—Å–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≤—Å—ñ—Ö —Ç–æ–≤–∞—Ä—ñ–≤
        return self.driver.page_source
    
    def parse_product_list(self, html):
        """–ü–∞—Ä—Å–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä—ñ–≤ –∑ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó"""
        soup = BeautifulSoup(html, 'html.parser')
        cards = soup.find_all('div', class_='stone_card')
        
        print(f"\nüîç –ó–Ω–∞–π–¥–µ–Ω–æ —Ç–æ–≤–∞—Ä—ñ–≤ –Ω–∞ —Å—Ç–æ—Ä—ñ–Ω—Ü—ñ: {len(cards)}")
        
        products = []
        for card in cards:
            try:
                link = card.find('a', class_='info')
                product_url = link['href'] if link else None
                
                # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –≤–∂–µ –æ–±—Ä–æ–±–ª–µ–Ω—ñ —Ç–æ–≤–∞—Ä–∏
                if product_url in self.processed_urls:
                    continue
                
                # –ù–∞–∑–≤–∞ —Ç–æ–≤–∞—Ä—É
                title = card.find('p', class_='stone_name')
                title_text = title.get('title', '') if title else ''
                
                # –ë—Ä–µ–Ω–¥
                brand = card.find('p', class_='stone_company')
                brand_text = brand.text.strip() if brand else ''
                
                # –ö–∞—Ä—Ç–∏–Ω–∫–∞
                img = card.find('img', class_='stone_cover')
                img_url = img['src'] if img else ''
                
                # –¢–∏–ø –ø–æ–≤–µ—Ä—Ö–Ω—ñ
                surface_type = card.find('div', class_='additional-info__title')
                surface_text = surface_type.find('span').text.strip() if surface_type and surface_type.find('span') else ''
                
                products.append({
                    'url': product_url,
                    'title': title_text,
                    'brand': brand_text,
                    'feature_photo': img_url,
                    'type': surface_text
                })
                
            except Exception as e:
                print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ –∫–∞—Ä—Ç–∫–∏: {e}")
                continue
        
        new_products = len(products)
        print(f"‚ú® –ù–æ–≤–∏—Ö —Ç–æ–≤–∞—Ä—ñ–≤ –¥–ª—è –æ–±—Ä–æ–±–∫–∏: {new_products}")
        
        return products
    
    def parse_product_detail(self, url, category_name):
        """–ü–∞—Ä—Å–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É —Å—Ç–æ—Ä—ñ–Ω–∫—É —Ç–æ–≤–∞—Ä—É"""
        max_retries = 3
        
        for attempt in range(max_retries):
            try:
                self.driver.get(url)
                time.sleep(2)
                
                html = self.driver.page_source
                soup = BeautifulSoup(html, 'html.parser')
                
                # –ö–æ–¥ —Ç–æ–≤–∞—Ä—É –∑ h1
                h1 = soup.find('h1')
                code = h1.text.strip() if h1 else ''
                
                # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ø–µ—Ä–µ–¥–∞–Ω—É –∫–∞—Ç–µ–≥–æ—Ä—ñ—é
                category = category_name
                
                # –ì–∞–ª–µ—Ä–µ—è –∑–æ–±—Ä–∞–∂–µ–Ω—å
                gallery_images = []
                gallery = soup.find('div', class_='gellery_for')
                
                if gallery:
                    # –®—É–∫–∞—î–º–æ –≤—Å—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –≤ —Å–ª–∞–π–¥–µ—Ä—ñ
                    images = gallery.find_all('img', {'data-fancybox': 'gallery'})
                    
                    for img in images[:5]:  # –ú–∞–∫—Å–∏–º—É–º 5 –∑–æ–±—Ä–∞–∂–µ–Ω—å
                        img_url = img.get('href') or img.get('src', '')
                        # –ë–µ—Ä–µ–º–æ –≤–µ–ª–∏–∫—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è (1280)
                        if img_url and '1280' in img_url:
                            gallery_images.append(img_url)
                        elif img_url:
                            # –Ø–∫—â–æ –Ω–µ–º–∞—î 1280, –Ω–∞–º–∞–≥–∞—î–º–æ—Å—å –∑–∞–º—ñ–Ω–∏—Ç–∏ —Ä–æ–∑–º—ñ—Ä
                            img_url = img_url.replace('/320/', '/1280/').replace('/540/', '/1280/')
                            gallery_images.append(img_url)
                
                # –î–æ–ø–æ–≤–Ω—é—î–º–æ –¥–æ 5 –µ–ª–µ–º–µ–Ω—Ç—ñ–≤ –ø–æ—Ä–æ–∂–Ω—ñ–º–∏ –∑–Ω–∞—á–µ–Ω–Ω—è–º–∏
                while len(gallery_images) < 5:
                    gallery_images.append('')
                
                return {
                    'code': code,
                    'category': category,
                    'gallery': gallery_images[:5]
                }
                
            except WebDriverException as e:
                if attempt < max_retries - 1:
                    print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –∑'—î–¥–Ω–∞–Ω–Ω—è, —Å–ø—Ä–æ–±–∞ {attempt + 2}/{max_retries}...")
                    self.restart_driver()
                    time.sleep(2)
                else:
                    print(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—å –æ–±—Ä–æ–±–∏—Ç–∏ {url}: {e}")
                    return {
                        'code': '',
                        'category': '',
                        'gallery': ['', '', '', '', '']
                    }
            except Exception as e:
                print(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ {url}: {e}")
                return {
                    'code': '',
                    'category': '',
                    'gallery': ['', '', '', '', '']
                }
    
    def save_product_to_excel(self, product_data):
        """–î–æ–¥–∞—î –æ–¥–∏–Ω —Ç–æ–≤–∞—Ä –¥–æ Excel —Ñ–∞–π–ª—É"""
        try:
            print(f"üíæ –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ç–æ–≤–∞—Ä—É: {product_data.get('Title', '–ë–µ–∑ –Ω–∞–∑–≤–∏')}")
            
            # –Ø–∫—â–æ —Ñ–∞–π–ª —ñ—Å–Ω—É—î, –¥–æ–ø–∏—Å—É—î–º–æ –¥–æ –Ω—å–æ–≥–æ
            if os.path.exists(self.output_file):
                print(f"   üìÇ –§–∞–π–ª —ñ—Å–Ω—É—î, –¥–æ–ø–∏—Å—É—î–º–æ...")
                # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ openpyxl –¥–ª—è —à–≤–∏–¥–∫–æ–≥–æ –¥–æ–ø–∏—Å—É–≤–∞–Ω–Ω—è
                from openpyxl import load_workbook
                
                wb = load_workbook(self.output_file)
                ws = wb['Products']
                
                # –î–æ–¥–∞—î–º–æ –Ω–æ–≤–∏–π —Ä—è–¥–æ–∫
                ws.append([
                    product_data['Brand'],
                    product_data['Category'],
                    product_data['Title'],
                    product_data['Code'],
                    product_data['Feature photo'],
                    product_data['Type'],
                    product_data['Gallery1'],
                    product_data['Gallery2'],
                    product_data['Gallery3'],
                    product_data['Gallery4'],
                    product_data['Gallery5']
                ])
                
                wb.save(self.output_file)
                wb.close()
                print(f"   ‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ!")
            else:
                print(f"   üÜï –°—Ç–≤–æ—Ä—é—î–º–æ –Ω–æ–≤–∏–π —Ñ–∞–π–ª...")
                # –°—Ç–≤–æ—Ä—é—î–º–æ –Ω–æ–≤–∏–π —Ñ–∞–π–ª –∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏
                df = pd.DataFrame([product_data])
                with pd.ExcelWriter(self.output_file, engine='openpyxl') as writer:
                    df.to_excel(writer, index=False, sheet_name='Products')
                    
                    # –ù–∞–ª–∞—à—Ç–æ–≤—É—î–º–æ —à–∏—Ä–∏–Ω—É –∫–æ–ª–æ–Ω–æ–∫
                    worksheet = writer.sheets['Products']
                    column_widths = {
                        'A': 20, 'B': 25, 'C': 30, 'D': 20, 'E': 50,
                        'F': 15, 'G': 50, 'H': 50, 'I': 50, 'J': 50, 'K': 50
                    }
                    for col, width in column_widths.items():
                        worksheet.column_dimensions[col].width = width
                print(f"   ‚úÖ –§–∞–π–ª —Å—Ç–≤–æ—Ä–µ–Ω–æ: {self.output_file}")
                        
        except Exception as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –≤ Excel: {e}")
            import traceback
            traceback.print_exc()
    
    def parse_all(self, categories):
        """–û—Å–Ω–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –ø–∞—Ä—Å–∏–Ω–≥—É"""
        print("üöÄ –ü–æ—á–∞—Ç–æ–∫ –ø–∞—Ä—Å–∏–Ω–≥—É topovi.com.ua\n")
        
        # –û–±—Ä–æ–±–ª—è—î–º–æ –∫–æ–∂–Ω—É –∫–∞—Ç–µ–≥–æ—Ä—ñ—é
        for category_name, category_url in categories.items():
            print(f"\n{'='*60}")
            print(f"üìÇ –û–±—Ä–æ–±–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó: {category_name}")
            print(f"üîó URL: {category_url}")
            print(f"{'='*60}\n")
            
            # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –≤—Å—ñ —Ç–æ–≤–∞—Ä–∏ –∑ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó
            html = self.load_all_products(category_url)
            
            # –ü–∞—Ä—Å–∏–º–æ —Å–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä—ñ–≤
            products = self.parse_product_list(html)
            
            if not products:
                print(f"‚úÖ –ù–µ–º–∞—î –Ω–æ–≤–∏—Ö —Ç–æ–≤–∞—Ä—ñ–≤ —É –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó '{category_name}'")
                continue
            
            # –û–±—Ä–æ–±–ª—è—î–º–æ –∫–æ–∂–µ–Ω —Ç–æ–≤–∞—Ä
            print(f"\nüì¶ –û–±—Ä–æ–±–∫–∞ –¥–µ—Ç–∞–ª—å–Ω–∏—Ö —Å—Ç–æ—Ä—ñ–Ω–æ–∫ —Ç–æ–≤–∞—Ä—ñ–≤ –∑ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó '{category_name}'...")
            
            for product in tqdm(products, desc=f"{category_name}"):
                if product['url'] and product['url'] not in self.processed_urls:
                    try:
                        print(f"\nüîç –û–±—Ä–æ–±–∫–∞: {product['title']}")
                        details = self.parse_product_detail(product['url'], category_name)
                        
                        # –§–æ—Ä–º—É—î–º–æ –¥–∞–Ω—ñ —Ç–æ–≤–∞—Ä—É
                        product_data = {
                            'Brand': product['brand'],
                            'Category': details['category'],
                            'Title': product['title'],
                            'Code': details['code'],
                            'Feature photo': product['feature_photo'],
                            'Type': product['type'],
                            'Gallery1': details['gallery'][0],
                            'Gallery2': details['gallery'][1],
                            'Gallery3': details['gallery'][2],
                            'Gallery4': details['gallery'][3],
                            'Gallery5': details['gallery'][4],
                        }
                        
                        print(f"   üìã –î–∞–Ω—ñ –∑—ñ–±—Ä–∞–Ω–æ: Brand={product_data['Brand']}, Code={product_data['Code']}")
                        
                        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ç–æ–≤–∞—Ä —É —Ñ–∞–π–ª
                        self.save_product_to_excel(product_data)
                        
                        # –î–æ–¥–∞—î–º–æ URL –¥–æ –æ–±—Ä–æ–±–ª–µ–Ω–∏—Ö
                        self.processed_urls.add(product['url'])
                        
                        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –ø—Ä–æ–≥—Ä–µ—Å –∫–æ–∂–Ω—ñ 10 —Ç–æ–≤–∞—Ä—ñ–≤
                        if len(self.processed_urls) % 10 == 0:
                            self.save_progress()
                        
                        # –ù–µ–≤–µ–ª–∏–∫–∞ –∑–∞—Ç—Ä–∏–º–∫–∞ –º—ñ–∂ –∑–∞–ø–∏—Ç–∞–º–∏
                        time.sleep(0.5)
                        
                    except Exception as e:
                        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ —Ç–æ–≤–∞—Ä—É: {e}")
                        self.save_progress()
                        continue
        
        # –§—ñ–Ω–∞–ª—å–Ω–µ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –ø—Ä–æ–≥—Ä–µ—Å—É
        self.save_progress()
        
        print(f"\n‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        print(f"üìä –í—Å—å–æ–≥–æ –æ–±—Ä–æ–±–ª–µ–Ω–æ —Ç–æ–≤–∞—Ä—ñ–≤: {len(self.processed_urls)}")
        print(f"üíæ –§–∞–π–ª –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {self.output_file}")
    
    def close(self):
        """–ó–∞–∫—Ä–∏–≤–∞—î –±—Ä–∞—É–∑–µ—Ä"""
        if self.driver:
            self.driver.quit()
    
    def reset_progress(self):
        """–°–∫–∏–¥–∞—î –ø—Ä–æ–≥—Ä–µ—Å (–¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥—É)"""
        if os.path.exists(self.progress_file):
            os.remove(self.progress_file)
        if os.path.exists(self.output_file):
            os.remove(self.output_file)
        self.processed_urls = set()
        print("üîÑ –ü—Ä–æ–≥—Ä–µ—Å —Å–∫–∏–Ω—É—Ç–æ")


def main():
    """–ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è"""
    parser = TopoviParser(output_file='topovi_products.xlsx')
    
    try:
        # –ö–∞—Ç–µ–≥–æ—Ä—ñ—ó –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥—É
        categories = {
            '–ö–≤–∞—Ä—Ü–æ–≤–∏–π –∫–∞–º—ñ–Ω—å': 'https://topovi.com.ua/stones/types=kvarcevyy-kamen',
            '–ù–∞—Ç—É—Ä–∞–ª—å–Ω–∏–π –∫–∞–º—ñ–Ω—å': 'https://topovi.com.ua/stones/types=naturalniy-kamin',
            '–ê–∫—Ä–∏–ª–æ–≤–∏–π –∫–∞–º—ñ–Ω—å': 'https://topovi.com.ua/stones/types=akrilovyy-kamen'
        }
        
        # –ó–∞–ø—É—Å–∫–∞—î–º–æ –ø–∞—Ä—Å–∏–Ω–≥
        parser.parse_all(categories)
        
    except KeyboardInterrupt:
        print("\n\n‚è∏Ô∏è –ü–∞—Ä—Å–∏–Ω–≥ –∑—É–ø–∏–Ω–µ–Ω–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–º")
        print("üíæ –ü—Ä–æ–≥—Ä–µ—Å –∑–±–µ—Ä–µ–∂–µ–Ω–æ. –î–ª—è –ø—Ä–æ–¥–æ–≤–∂–µ–Ω–Ω—è –∑–∞–ø—É—Å—Ç—ñ—Ç—å —Å–∫—Ä–∏–ø—Ç –∑–Ω–æ–≤—É")
    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞: {e}")
        print("üíæ –ü—Ä–æ–≥—Ä–µ—Å –∑–±–µ—Ä–µ–∂–µ–Ω–æ. –î–ª—è –ø—Ä–æ–¥–æ–≤–∂–µ–Ω–Ω—è –∑–∞–ø—É—Å—Ç—ñ—Ç—å —Å–∫—Ä–∏–ø—Ç –∑–Ω–æ–≤—É")
    finally:
        parser.save_progress()
        parser.close()


if __name__ == "__main__":
    main()